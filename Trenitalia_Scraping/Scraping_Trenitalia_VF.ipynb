{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1575e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalisation du driver\n",
    "service = Service('msedgedriver.exe')\n",
    "driver = webdriver.Edge(service=service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8757f3ff",
   "metadata": {},
   "source": [
    "### Fonctions utilisées pour la page d'accueil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2cdfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_date(driver) :\n",
    "    \"\"\"Cette fonction permet de rechercher et sélectionner la date du 1er mai\n",
    "    dans le calendrier du site tout en évitant les erreur du type ElementNotInteractable et ElementNotFound\"\"\"\n",
    "    \n",
    "    find = False\n",
    "    # Tant que le mois de mai n'est pas trouvé dans le calendrier, on continue à chercher\n",
    "    while find == False :\n",
    "        # Extraire le code source html et vérifier si le mois de mai est présent\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,\"html.parser\")\n",
    "        elements = soup.find_all(class_='ui-datepicker-month')\n",
    "        for element in elements :\n",
    "            if 'Mai' in element.get_text():\n",
    "                find = True # cela signifie qu'on a trouvé le mois de mai on pourra donc sortir d\n",
    "        if find != True:\n",
    "            # On essaie de cliquer sur la flèche pour changer de mois\n",
    "            try :\n",
    "                arrow_element = driver.find_element(By.CLASS_NAME,'ui-datepicker-next.ui-corner-all')\n",
    "                arrow_element.click()\n",
    "            except :\n",
    "                print(\"Unable to change the month on the calendar\")\n",
    "                # Comme on a pas pu changer de mois, on essaie de cliquer à nouveau sur le calendrier\n",
    "                try :\n",
    "                    calendar = driver.find_element(By.ID,'biglietti_data_pVISIBLE')\n",
    "                    calendar.click()\n",
    "                except:\n",
    "                    print(\"Calendar not found\")\n",
    "                    \n",
    "                \n",
    "    # Choisir le 1er mai\n",
    "    driver.find_element(By.XPATH,'//*[@id=\"ui-datepicker-div\"]/div[2]/table/tbody/tr[1]/td[3]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac2de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_in_homepage(driver,depart,arrivee):\n",
    "    \"\"\" Cette fonction permet de naviguer sur la page d'accueil de trenitalia en indiquant la date sur le calendrier, la gare\n",
    "    de départ et d'arrivée, l'heure et enfin de cliquer sur rechercher pour aller vers la page suivante des horaires\"\"\"\n",
    "    \n",
    "    web_link= \"https://www.trenitalia.com/trenitalia-france.html\"\n",
    "    driver.get(web_link)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Désactivation des cookies\n",
    "    try : \n",
    "        cookies = driver.find_element(By.ID,'onetrust-reject-all-handler')\n",
    "        cookies.click()\n",
    "    except:\n",
    "        print(\"cookie not found\")\n",
    "\n",
    "    # Sélectionner la date 1er mai à partir du calendrier\n",
    "    Find_date(driver)\n",
    "\n",
    "    # Trouvez les champs de la gare de départ et de la gare d'arrivée\n",
    "    depart = driver.find_element(by='id',value ='biglietti_fromNew')\n",
    "    arrivee = driver.find_element(by='id',value ='biglietti_toNew')\n",
    "\n",
    "    # Ecrire le nom des gares de départ et d'arrivée\n",
    "    depart.send_keys(departure)\n",
    "    arrivee.send_keys(arrival)\n",
    "\n",
    "    # Sélectionner le bouton heure\n",
    "    driver.find_element(By.XPATH,'//*[@id=\"biglietti_ora_p_but\"]').click()\n",
    "    time.sleep(0.5)\n",
    "    # Sélectionner l'heure minuit\n",
    "    driver.find_element(By.XPATH,'//*[@id=\"1p\"]').click()\n",
    "    # Cliquer sur le bouton rechercher pour aller sur la page des horaires du trajet \n",
    "    button = driver.find_element(By.XPATH,'//*[@id=\"sub-and-carnet\"]/button')\n",
    "    button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64848bdc",
   "metadata": {},
   "source": [
    "### Fonctions utilisées pour la page des horaires de trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_month(driver):\n",
    "    \"\"\"Cette fonction permet de récupérer le mois et la date sélectionné (curseur positionné) sur la page des horaires\n",
    "    Elle permet d'éviter l'erreur AttributeError lors du scraping \"\"\"\n",
    "    \n",
    "    date_selected = None\n",
    "    mois_selected = None\n",
    "    \n",
    "    # Tant que le mois et la date n'ont pas été trouvé on continue d'essayer de le trouver avec beautifoulSoup\n",
    "    while(date_selected is None and mois_selected is None) :\n",
    "        # Récupération du code html de la page web\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,\"html.parser\")\n",
    "        \n",
    "        try :\n",
    "            # On essaie de récupérer le jour et le mois\n",
    "            date_selected = soup.find('div',{'class':'card card-calendar au-target'}) \\\n",
    "                .find('li',{'class':'au-target nav-item today cursor-pointer'}) \\\n",
    "                .find('div',{\"class\": \"align-items-center h-100 d-none d-sm-flex\"}) \\\n",
    "                .find('strong',{'class':'au-target day-number'}).get_text(strip=True)\n",
    "\n",
    "            # Récupération du mois sélectionné\n",
    "            mois_selected = soup.find('div',{'class':'card card-calendar au-target'}) \\\n",
    "                .find('li',{'class':'au-target nav-item today cursor-pointer'}) \\\n",
    "                .find('div',{\"class\": \"align-items-center h-100 d-none d-sm-flex\"}) \\\n",
    "                .find('strong',{'class':'au-target month'}).get_text(strip=True)\n",
    "        except:\n",
    "            # L'except permet d'éviter l'erreur Attribute error rencontrée à de multiples reprises qui bloque le scraping.\n",
    "            # Cette erreur est dûe au fait que la page web contenant les horaires mets du temps à s'afficher \n",
    "            # ce qui explique l'utilisation de la boucle while\n",
    "            print(\"Date and month not found\")\n",
    "            \n",
    "    return date_selected,mois_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_down(driver):\n",
    "    \"\"\"Cette fonction permet de scroller complètement vers le bas pour récupérer l'ensemble des horaires de train \n",
    "    sur la même page web\"\"\"\n",
    "    \n",
    "    scroll =True\n",
    "    # On scrolle vers le bas tant qu'il reste encore d'autres horaires sur la page web\n",
    "    while scroll ==True:\n",
    "        # On scrolle complètement vers le bas\n",
    "        height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "        time.sleep(3)\n",
    "        # Récupération du code html de la page web\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,\"html.parser\")\n",
    "        # On recherche l'élement el qui indique si d'autres horaires de trains sont présentes sur la page web\n",
    "        el = soup.find('div',attrs = {'class':'col-12 text-center mt-2 au-target'})\n",
    "        if el==None :\n",
    "            scroll = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af748e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_date(driver) :\n",
    "    \"\"\" Cette fonction permet de changer de date sur la page web des horaires d'un même trajet \"\"\"\n",
    "    \n",
    "    # On revient tout en haut de la page web\n",
    "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "    time.sleep(2)\n",
    "    date_changed = False\n",
    "    # On essaie de changer la date tant que cela ne fonctionne pas\n",
    "    while date_changed == False :\n",
    "        if date_changed != True:\n",
    "            next_date = driver.find_element(By.ID,'forwardDays')\n",
    "            try :\n",
    "                next_date.click()\n",
    "                date_changed = True\n",
    "            except :\n",
    "                print(\"Date not changed\")\n",
    "                # Ables to avoid element not interactable\n",
    "                date_changed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495f5ae6",
   "metadata": {},
   "source": [
    "### Scraping de l'ensemble des trajets de façon automatique\n",
    "Ce code utilise l'ensemble des fonctions présentées ci-dessus pour scraper le site internet trenitalia sans générer d'erreurs et de façon automatique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f19c6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Généralisation pour l'automatiser sur l'intégralité des stations\n",
    "\n",
    "# Initialisation des listes contenants chacune une colonne du dataframe contenant l'ensemble des données\n",
    "prix = []\n",
    "station_departure = []\n",
    "station_arrival = []\n",
    "traject_lenght = []\n",
    "date_departure = []\n",
    "hour_departure = []\n",
    "hour_arrival = []\n",
    "\n",
    "# Noms des trajets à scraper (listes de tuples de stations)\n",
    "routes = [\n",
    "    (\"Venezia ( Tutte Le Stazioni )\", \"Napoli ( Tutte Le Stazioni )\"),\n",
    "    (\"Venezia ( Tutte Le Stazioni )\", \"Bari ( Tutte Le Stazioni )\"),\n",
    "    (\"Milano ( Tutte Le Stazioni )\", \"Bari ( Tutte Le Stazioni )\"),\n",
    "    (\"Milano ( Tutte Le Stazioni )\", \"Napoli ( Tutte Le Stazioni )\"),\n",
    "    (\"Milano ( Tutte Le Stazioni )\", \"Pescara Centrale\"),\n",
    "    (\"Roma ( Tutte Le Stazioni )\", \"Bari ( Tutte Le Stazioni )\"),\n",
    "    (\"Roma ( Tutte Le Stazioni )\", \"Palermo ( Tutte Le Stazioni )\"),\n",
    "    (\"Napoli ( Tutte Le Stazioni )\", \"Genova ( Tutte Le Stazioni )\"),\n",
    "    (\"Napoli ( Tutte Le Stazioni )\", \"Palermo ( Tutte Le Stazioni )\"),\n",
    "    (\"Napoli ( Tutte Le Stazioni )\", \"Torino ( Tutte Le Stazioni )\"),\n",
    "    (\"Torino ( Tutte Le Stazioni )\", \"Bari ( Tutte Le Stazioni )\")\n",
    "]\n",
    "\n",
    "# Pour chaque trajet\n",
    "for departure, arrival in routes:\n",
    "    #On navige dans la page d'accueil vers les horaires\n",
    "    navigate_in_homepage(driver,departure,arrival)\n",
    "    time.sleep(3)\n",
    "    stop_scrap = False\n",
    "    \n",
    "    # On scrappe l'intégralité du mois de mai (la variable stop_scrap permet de s'en assurer)\n",
    "    while stop_scrap == False :\n",
    "        # On récupère la date et le mois ou le curseur est positionné sur la page des horaires\n",
    "        date_selected, mois_selected = get_date_month(driver)\n",
    "        \n",
    "        # Arrêt du scraping pour la route concernée si on est plus en mai on va sortir de la boucle while et changer de trajet\n",
    "        if mois_selected !='MAI' :\n",
    "            stop_scrap = True\n",
    "\n",
    "        else :\n",
    "            # On scrolle complètement vers le bas la page web\n",
    "            scroll_down(driver)\n",
    "            time.sleep(3)\n",
    "            # Récupération du code html\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html,\"html.parser\")\n",
    "            # Récupération du div contenant l'ensemble des trains\n",
    "            div = soup.find('div', {'id': 'solution-accordion','class':'w-100'})\n",
    "            # récupération des trains de la page\n",
    "            trains = div.find_all('div',attrs = {'class':'row au-target','role':'region'})\n",
    "            # Pour chaque train\n",
    "            for train in trains :\n",
    "                try :\n",
    "                    # Si le trajet n'a pas de correspondances on récupère les données \n",
    "                    if 'correspondance' not in train.find('b',{'class':'au-target'}).get_text(strip=True):\n",
    "                        # Prix\n",
    "                        prix.append(train.find('title2',{'class' : 'black text-primary ml-1 mb-0'}).get_text(strip=True))\n",
    "                        # Gare de départ\n",
    "                        station_departure.append(train.find('div',{'class' : 'col-4 text-nowrap'}).get_text(strip=True))\n",
    "                        # Gare d'arrivée\n",
    "                        station_arrival.append(train.find('div',{'class' : 'au-target col-3 offset-5 pl-0 text-nowrap'}).get_text(strip=True))\n",
    "                        # Durée du trajet\n",
    "                        traject_lenght.append(train.find('caption1',{'class' : 'text-dark center mx-3'}).get_text(strip=True))\n",
    "                        # Heure de départ\n",
    "                        hour_departure.append(train.find('body2',{'class' : 'text-secondary bold m-0 mr-3'}).get_text(strip=True))\n",
    "                        # Heure d'arrivée\n",
    "                        hour_arrival.append(train.find('body2',{'class' : 'text-secondary bold m-0 ml-3'}).get_text(strip=True))\n",
    "                        # Date de départ\n",
    "                        date_departure.append(datetime(year=2024, month=5, day=int(date_selected)))\n",
    "                except :\n",
    "                    # Cas ou l'on ne trouve pas de trajets sans correspondance\n",
    "                    print(\"Not found\")\n",
    "            # Changement de la date sur la page des horaires\n",
    "            change_date(driver)\n",
    "            \n",
    "# Récupération de l'ensemble des données dans un dataframe converti ensuite en csv          \n",
    "data = {\n",
    "    'station_departure': station_departure,\n",
    "    'station_arrival': station_arrival,\n",
    "    'hour_departure': hour_departure,\n",
    "    'hour_arrival': hour_arrival,\n",
    "    'date_departure': date_departure,\n",
    "    'traject_lenght': traject_lenght,\n",
    "    'prix': prix,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"trenitalia_data.csv\")\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
